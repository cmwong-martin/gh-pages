<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Light RNN - compress your RNN model from 80GB to 50MB</title>
    <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Source+Sans+Pro:300,300i,600">
    <link href="/gh-pages/resources/font-awesome/css/font-awesome.min.css" rel="stylesheet">
    <link rel="stylesheet" href="/gh-pages/style.css">
    <link rel="alternate" type="application/rss+xml" title="RSS Feed for CHI MAN WONG" href="/gh-pages/feed.xml" />
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
    </script>
    <script type="text/javascript" async
      src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML">
    </script>
</head>


<body class="preload">
    <div class="top"></div>
    <div class="profile" style="background-image: url(http://apple.wallpapersfine.com/wallpapers/original/1242x2208/w-5273.jpg);">
        <img src="/gh-pages/image.jpg" class="img-circle" />
        <h3>CHI MAN WONG</h3>
        <p>A passionate CS master student in deep learning</p>
        <ul class="social">
            
            <a type="button" href="http://github.com/cmwong-martin">
                <i class="fa fa-github"></i>
            </a>
                
        </ul>
    </div>
    <div class="posts">
        <header class="bloghead">
<nav class="bloghead-nav">
    
    <a href="/gh-pages">Home<span> &nbsp;/&nbsp; </span></a> 
    <a href="/gh-pages/about">About<span> &nbsp;/&nbsp; </span></a> 
</nav>
</header>

<div class="content post">
  <p></p>
  <h3 class="post-title" style="display: inline;">Light RNN - compress your RNN model from 80GB to 50MB</h3>
  <div class="post-date">
    <time>15 Dec 2016</time>
  </div>
  <hr>
  <h3 id="problem">Problem</h3>
<p>Large RNN model is common but it is <strong>infeasible</strong> to</p>

<ol>
  <li>fit into the memory of GPU devices.</li>
  <li>host in mobile devices for efficient inferences.</li>
</ol>

<h3 id="example">Example</h3>
<p>Consider the ClueWeb dataset [1], the vocabulary contains over 10M words. Then, the size of the input embedding matrix will be <strong>~40GB</strong>. And consider the output embedding matrix and those weights between hidden layers, the RNN model will be <strong>&gt;80GB</strong>, which is much exceeding the capacity of current GPU (8GB).</p>

<h3 id="proposed-method">Proposed Method</h3>
<p>Consider the Figure 1., the left table is the traditional representation of each vocabulary. The middle table is the proposed two-component representation [2] for each vocabulary.  The right one shows how each vocabulary shares two components: a row vector and a column vector.</p>

<p><img src="/gh-pages/table/twoComponentTable.png" alt="example image" class="center-image" /></p>

<h3 id="advantages">Advantages</h3>
<p>Using two-component representation to a vocabulary of <script type="math/tex">|V|</script> unique words, only <script type="math/tex">2{\sqrt {|V|}}</script> vectors are needed. Therefore, the proposed method only requires <script type="math/tex">2{\sqrt {|V|}}</script> vectors to represent a vocabulary is far less than <script type="math/tex">|V|</script> required by existing approaches.</p>

<h3 id="disadvantages">Disadvantages</h3>
<p>The architecture of the proposed RNN model is shown in Figure 2 Left. The RNN model now needs to model two components for a single hidden layer: row <script type="math/tex">X^r</script> and column <script type="math/tex">X^c</script>, leading to a more complex model.</p>

<p><img src="/gh-pages/figure/twoComponentRNN.png" alt="example image" class="center-image" /></p>

<h3 id="result">Result</h3>

<p><img src="/gh-pages/table/twoComponentRNN2.png" alt="example image" class="center-image" /></p>

<p><img src="/gh-pages/table/twoComponentRNN3.png" alt="example image" class="center-image" /></p>

<h3 id="reference">Reference</h3>

<ol>
  <li>Pomikálek, Jan, Milos Jakubícek, and Pavel Rychlý. “Building a 70 billion word corpus of English from ClueWeb.” LREC. 2012.</li>
  <li>Xiang Li, Tao Qin, Jian Yang, and Tie-Yan Liu, Lightrnn: Memory and computation-efficient recurrent neural networks, CoRR abs/1610.09893 (2016).</li>
</ol>

</div>


<div id="related">
  <h3>Related Posts</h3>
    
      <p>20 Dec 2016 &raquo;<a href="/gh-pages/2016/12/20/duallearn/">Dual Learning Mechanism - train your translation model without any human labelling</a></p>
    
</div>

    </div>
</body>
<script type="text/javascript">
    window.onload = function(){
        document.getElementsByTagName("BODY")[0].classList.remove("preload");
    }
</script>
</html>
